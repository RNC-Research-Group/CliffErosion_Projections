{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Setting up the code and installing required packages \n",
    "from util import *\n",
    "from glob import glob\n",
    "import matplotlib.pyplot as plt\n",
    "from shapely import wkt\n",
    "from shapely.geometry import LineString, Polygon\n",
    "pd.set_option(\"display.max_columns\", None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Navigate to intersects shapefile and separates out the year, finds how many years from 1800 and how many years to 2100\n",
    "gdf = gpd.read_file(f\"Data/Merged Intersects_UniqueID/NorthIsland_Intersects.shp\")\n",
    "gdf[\"Date\"] = pd.to_datetime(gdf.ShorelineI, dayfirst=True, format='mixed')\n",
    "gdf[\"Year\"] = gdf.Date.dt.year\n",
    "gdf[\"YearsSinceBase\"] = (gdf.Date - pd.Timestamp(1800, 1, 1)).dt.days / 365.25\n",
    "gdf[\"YearsUntilFuture\"] = (\n",
    "    pd.Timestamp(2100, 1, 1) - gdf.Date\n",
    "    ).dt.days / 365.25\n",
    "gdf.Date = gdf.Date.astype(str)\n",
    "gdf[\"TransectID\"] = gdf.Unique_ID.astype(np.int64)\n",
    "gdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_transects(intersects):\n",
    "  p1 = intersects.geometry[intersects.Distance.idxmin()].coords[0]\n",
    "  p2 = intersects.geometry[intersects.Distance.idxmax()].coords[0]\n",
    "  azimuth = math.degrees(math.atan2(p1[0]-p2[0], p1[1]-p2[1]))\n",
    "  if azimuth < 0:\n",
    "      azimuth += 360\n",
    "  return pd.Series({\"Azimuth\": azimuth, \"geometry\": LineString([p1, p2])})\n",
    "\n",
    "lines = gdf.groupby(\"TransectID\")[[\"geometry\", \"Distance\"]].apply(get_transects)\n",
    "lines.crs = gdf.crs\n",
    "lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lines[\"dist_to_neighbour\"] = lines.distance(lines.shift(-1))\n",
    "breakpoints = lines.dist_to_neighbour[lines.dist_to_neighbour > 105]\n",
    "lines[\"group\"] = pd.Series(range(len(breakpoints)), index=breakpoints.index)\n",
    "lines[\"group\"] = lines.group.bfill().fillna(len(breakpoints)).astype(int)\n",
    "transect_metadata = lines[[\"Azimuth\", \"group\"]].to_dict(orient=\"index\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Linear regression is run here. See util.py for the breakdown on linear_models\n",
    "linear_models = fit(gdf, transect_metadata)\n",
    "linear_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Only run if rolling average is needed. Otherwise SKIP THIS\n",
    "#linear_models = fit(gdf, transect_metadata)\n",
    "#rolled_slopes = linear_models.groupby(\"group\").slope.rolling(10, min_periods=1).mean().dropna().reset_index(level=0)\n",
    "#linear_models.slope = rolled_slopes.slope\n",
    "#linear_models.dropna(inplace=True)\n",
    "#linear_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Coordinates of the projected shoreline are plotted here\n",
    "\n",
    "#Changed coordinate function by making old_x and old_y negative \n",
    "def calculate_new_coordinates(old_x, old_y, bearing, distance):\n",
    "    bearing_radians = math.radians(bearing)\n",
    "    new_x = old_x + (distance * math.sin(bearing_radians))\n",
    "    new_y = old_y + (distance * math.cos(bearing_radians))\n",
    "    point = Point(new_x, new_y)\n",
    "    assert not point.is_empty\n",
    "    return point\n",
    "\n",
    "#Removed other model equations and changed Azimuth addtion from 180 to 360 deg\n",
    "def predict(\n",
    "    df: pd.DataFrame,\n",
    "    linear_models: pd.DataFrame,\n",
    "    transect_metadata: dict,\n",
    "):\n",
    "    \"\"\"_summary_\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): dataframe with columns: TransectID, Date, Distance, YearsSinceBase\n",
    "        linear_models (pd.DataFrame): dataframe with columns: TransectID, slope, intercept\n",
    "        transect_metadata (dict): dict lookup of TransectID to Azimuth & group\n",
    "        \n",
    "    Returns:\n",
    "        pd.DataFrame: resulting prediction points for the year 2100\n",
    "    \"\"\"\n",
    "    results = []\n",
    "    for i, row in linear_models.iterrows():\n",
    "        transect_ID = row.TransectID\n",
    "        transect_df = df[df.TransectID == transect_ID]\n",
    "        latest_row = transect_df[transect_df.Date == transect_df[\"Date\"].max()].iloc[0]\n",
    "        future_year = int(row.get(\"FUTURE_YEAR\", FUTURE_YEAR))\n",
    "        result = row.to_dict()\n",
    "        result.update({\n",
    "            \"TransectID\": transect_ID,\n",
    "            \"BaselineID\": latest_row.BaselineID,\n",
    "            \"group\": row.group,\n",
    "            \"Year\": future_year,\n",
    "            \"ocean_point\": calculate_new_coordinates(\n",
    "                latest_row.geometry.x,\n",
    "                latest_row.geometry.y,\n",
    "                transect_metadata[transect_ID][\"Azimuth\"] + 180,\n",
    "                500,\n",
    "            ),\n",
    "        })\n",
    "        \n",
    "        model = \"linear\"\n",
    "        slope = row.slope\n",
    "        intercept = row.intercept\n",
    "\n",
    "        predicted_distance = slope * (future_year - 1800) + intercept\n",
    "        distance_difference = latest_row.Distance - predicted_distance\n",
    "        result[f\"{model}_model_point\"] = calculate_new_coordinates(\n",
    "            latest_row.geometry.x,\n",
    "            latest_row.geometry.y,\n",
    "            transect_metadata[transect_ID][\"Azimuth\"],\n",
    "            distance_difference,\n",
    "        )\n",
    "        result[f\"{model}_model_predicted_distance\"] = predicted_distance\n",
    "        result[f\"{model}_model_distance\"] = distance_difference\n",
    "        results.append(result)\n",
    "    results = gpd.GeoDataFrame(results)\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Projection file is created here with the stats and coordinate points in table format\n",
    "results = predict(gdf, linear_models, transect_metadata)\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Spatial reference added to the results\n",
    "results.set_geometry(\"linear_model_point\", inplace=True, crs=2193)\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Line and polygon shapefiles are created here \n",
    "def prediction_results_to_line_polygon(results: gpd.GeoDataFrame):\n",
    "    lines = []\n",
    "    polygons = []\n",
    "    for group_name, group_data in results.groupby([\"BaselineID\", \"group\"]):\n",
    "        if len(group_data) > 1:\n",
    "            # Convert the points to LineString\n",
    "            line = LineString(list(group_data.geometry))\n",
    "            lines.append(line)\n",
    "            # Convert the points to a closed Polygon\n",
    "            polygon = Polygon(list(group_data.geometry) + list(group_data.ocean_point)[::-1])\n",
    "            polygons.append(polygon)\n",
    "    lines = gpd.GeoSeries(lines, crs=2193)\n",
    "    polygons = gpd.GeoSeries(polygons, crs=2193)\n",
    "    return lines, polygons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lines, poly = prediction_results_to_line_polygon(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Saving line and polygon projection file to Z drive. Change file location accordingly  \n",
    "lines, poly = prediction_results_to_line_polygon(results)\n",
    "lines.to_file(\"Z:\\Lalita\\RNC Cont\\......\\BigBay_projection_output_lines.shp\")\n",
    "poly.to_file(\"Z:\\Lalita\\RNC Cont\\.......\\BigBay_projection_output_polygon.shp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Saving line and polygon projection file to folder in VS Code. Change file location accordingly\n",
    "lines, poly = prediction_results_to_line_polygon(results)\n",
    "lines.to_file(\"Projections\\NorthIsland_projection_output_lines.shp\")\n",
    "poly.to_file(\"Projections\\NorthIsland_projection_output_polygon.shp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Quick visualisation of projected polygon and historic shorelines \n",
    "m = poly.explore(tiles=\"Esri.WorldImagery\")\n",
    "gpd.GeoDataFrame(results.drop(columns=[\"ocean_point\", \"linear_model_point\"]), geometry=results.linear_model_point).explore(m=m)\n",
    "gdf.explore(\"Year\", legend=True, m=m)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "environment",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
