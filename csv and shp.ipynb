{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "\n",
    "def combine_csvs(input_folder, output_file):\n",
    "    all_csvs = glob.glob(os.path.join(input_folder, '**/*.csv'), recursive=True)\n",
    "\n",
    "    if not all_csvs:\n",
    "        print(\"No CSV files found.\")\n",
    "        return\n",
    "\n",
    "    combined_csv = pd.concat([pd.read_csv(csv) for csv in all_csvs], ignore_index=True)\n",
    "    combined_csv.to_csv(output_file, index=False)\n",
    "    print(f\"Combined {len(all_csvs)} CSV files into {output_file}\")\n",
    "\n",
    "def combine_shapefiles(input_folder, output_file):\n",
    "    all_shps = glob.glob(os.path.join(input_folder, '**/*.shp'), recursive=True)\n",
    "\n",
    "    if not all_shps:\n",
    "        print(\"No Shapefiles found.\")\n",
    "        return\n",
    "\n",
    "    combined_shp = gpd.GeoDataFrame(pd.concat([gpd.read_file(shp) for shp in all_shps], ignore_index=True))\n",
    "    combined_shp.to_file(output_file, driver='ESRI Shapefile')\n",
    "    print(f\"Combined {len(all_shps)} Shapefiles into {output_file}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    input_folder = \"C:/Riskscape_Projects/getting-started/output\"\n",
    "    output_csv = \"C:/Riskscape_Projects/getting-started/output/combined.csv\"\n",
    "    output_shp = \"C:/Riskscape_Projects/getting-started/output/combined.shp\"\n",
    "\n",
    "    combine_csvs(input_folder, output_csv)\n",
    "    combine_shapefiles(input_folder, output_shp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lalit\\AppData\\Local\\Temp\\ipykernel_24300\\1584034119.py:19: DtypeWarning: Columns (0) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(csv)\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "can only concatenate str (not \"int\") to str",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\lalit\\GitHub\\Shoreline_Projections\\csv and shp.ipynb Cell 2\u001b[0m line \u001b[0;36m3\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/lalit/GitHub/Shoreline_Projections/csv%20and%20shp.ipynb#W1sZmlsZQ%3D%3D?line=34'>35</a>\u001b[0m input_folder \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mC:/Riskscape_Projects/getting-started/output\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/lalit/GitHub/Shoreline_Projections/csv%20and%20shp.ipynb#W1sZmlsZQ%3D%3D?line=35'>36</a>\u001b[0m output_csv \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mC:/Riskscape_Projects/getting-started/output/combined_sum_2.csv\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/lalit/GitHub/Shoreline_Projections/csv%20and%20shp.ipynb#W1sZmlsZQ%3D%3D?line=37'>38</a>\u001b[0m combine_csvs(input_folder, output_csv)\n",
      "\u001b[1;32mc:\\Users\\lalit\\GitHub\\Shoreline_Projections\\csv and shp.ipynb Cell 2\u001b[0m line \u001b[0;36m2\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/lalit/GitHub/Shoreline_Projections/csv%20and%20shp.ipynb#W1sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m df \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mread_csv(csv)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/lalit/GitHub/Shoreline_Projections/csv%20and%20shp.ipynb#W1sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m \u001b[39m# Sum the values in each column\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/lalit/GitHub/Shoreline_Projections/csv%20and%20shp.ipynb#W1sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m sum_series \u001b[39m=\u001b[39m df\u001b[39m.\u001b[39;49msum()\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/lalit/GitHub/Shoreline_Projections/csv%20and%20shp.ipynb#W1sZmlsZQ%3D%3D?line=23'>24</a>\u001b[0m \u001b[39m# Get the folder name from the file path\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/lalit/GitHub/Shoreline_Projections/csv%20and%20shp.ipynb#W1sZmlsZQ%3D%3D?line=24'>25</a>\u001b[0m folder_name \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mbasename(os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mdirname(csv))\n",
      "File \u001b[1;32mc:\\Users\\lalit\\anaconda3\\envs\\environment\\lib\\site-packages\\pandas\\core\\frame.py:11315\u001b[0m, in \u001b[0;36mDataFrame.sum\u001b[1;34m(self, axis, skipna, numeric_only, min_count, **kwargs)\u001b[0m\n\u001b[0;32m  11306\u001b[0m \u001b[39m@doc\u001b[39m(make_doc(\u001b[39m\"\u001b[39m\u001b[39msum\u001b[39m\u001b[39m\"\u001b[39m, ndim\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m))\n\u001b[0;32m  11307\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39msum\u001b[39m(\n\u001b[0;32m  11308\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m  11313\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs,\n\u001b[0;32m  11314\u001b[0m ):\n\u001b[1;32m> 11315\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39msum(axis, skipna, numeric_only, min_count, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m  11316\u001b[0m     \u001b[39mreturn\u001b[39;00m result\u001b[39m.\u001b[39m__finalize__(\u001b[39mself\u001b[39m, method\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39msum\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\lalit\\anaconda3\\envs\\environment\\lib\\site-packages\\pandas\\core\\generic.py:12055\u001b[0m, in \u001b[0;36mNDFrame.sum\u001b[1;34m(self, axis, skipna, numeric_only, min_count, **kwargs)\u001b[0m\n\u001b[0;32m  12047\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39msum\u001b[39m(\n\u001b[0;32m  12048\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[0;32m  12049\u001b[0m     axis: Axis \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m  12053\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs,\n\u001b[0;32m  12054\u001b[0m ):\n\u001b[1;32m> 12055\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_min_count_stat_function(\n\u001b[0;32m  12056\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39msum\u001b[39m\u001b[39m\"\u001b[39m, nanops\u001b[39m.\u001b[39mnansum, axis, skipna, numeric_only, min_count, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs\n\u001b[0;32m  12057\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\lalit\\anaconda3\\envs\\environment\\lib\\site-packages\\pandas\\core\\generic.py:12038\u001b[0m, in \u001b[0;36mNDFrame._min_count_stat_function\u001b[1;34m(self, name, func, axis, skipna, numeric_only, min_count, **kwargs)\u001b[0m\n\u001b[0;32m  12035\u001b[0m \u001b[39melif\u001b[39;00m axis \u001b[39mis\u001b[39;00m lib\u001b[39m.\u001b[39mno_default:\n\u001b[0;32m  12036\u001b[0m     axis \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[1;32m> 12038\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_reduce(\n\u001b[0;32m  12039\u001b[0m     func,\n\u001b[0;32m  12040\u001b[0m     name\u001b[39m=\u001b[39;49mname,\n\u001b[0;32m  12041\u001b[0m     axis\u001b[39m=\u001b[39;49maxis,\n\u001b[0;32m  12042\u001b[0m     skipna\u001b[39m=\u001b[39;49mskipna,\n\u001b[0;32m  12043\u001b[0m     numeric_only\u001b[39m=\u001b[39;49mnumeric_only,\n\u001b[0;32m  12044\u001b[0m     min_count\u001b[39m=\u001b[39;49mmin_count,\n\u001b[0;32m  12045\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\lalit\\anaconda3\\envs\\environment\\lib\\site-packages\\pandas\\core\\frame.py:11207\u001b[0m, in \u001b[0;36mDataFrame._reduce\u001b[1;34m(self, op, name, axis, skipna, numeric_only, filter_type, **kwds)\u001b[0m\n\u001b[0;32m  11203\u001b[0m     df \u001b[39m=\u001b[39m df\u001b[39m.\u001b[39mT\n\u001b[0;32m  11205\u001b[0m \u001b[39m# After possibly _get_data and transposing, we are now in the\u001b[39;00m\n\u001b[0;32m  11206\u001b[0m \u001b[39m#  simple case where we can use BlockManager.reduce\u001b[39;00m\n\u001b[1;32m> 11207\u001b[0m res \u001b[39m=\u001b[39m df\u001b[39m.\u001b[39;49m_mgr\u001b[39m.\u001b[39;49mreduce(blk_func)\n\u001b[0;32m  11208\u001b[0m out \u001b[39m=\u001b[39m df\u001b[39m.\u001b[39m_constructor_from_mgr(res, axes\u001b[39m=\u001b[39mres\u001b[39m.\u001b[39maxes)\u001b[39m.\u001b[39miloc[\u001b[39m0\u001b[39m]\n\u001b[0;32m  11209\u001b[0m \u001b[39mif\u001b[39;00m out_dtype \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m out\u001b[39m.\u001b[39mdtype \u001b[39m!=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mboolean\u001b[39m\u001b[39m\"\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\lalit\\anaconda3\\envs\\environment\\lib\\site-packages\\pandas\\core\\internals\\managers.py:1459\u001b[0m, in \u001b[0;36mBlockManager.reduce\u001b[1;34m(self, func)\u001b[0m\n\u001b[0;32m   1457\u001b[0m res_blocks: \u001b[39mlist\u001b[39m[Block] \u001b[39m=\u001b[39m []\n\u001b[0;32m   1458\u001b[0m \u001b[39mfor\u001b[39;00m blk \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mblocks:\n\u001b[1;32m-> 1459\u001b[0m     nbs \u001b[39m=\u001b[39m blk\u001b[39m.\u001b[39;49mreduce(func)\n\u001b[0;32m   1460\u001b[0m     res_blocks\u001b[39m.\u001b[39mextend(nbs)\n\u001b[0;32m   1462\u001b[0m index \u001b[39m=\u001b[39m Index([\u001b[39mNone\u001b[39;00m])  \u001b[39m# placeholder\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\lalit\\anaconda3\\envs\\environment\\lib\\site-packages\\pandas\\core\\internals\\blocks.py:377\u001b[0m, in \u001b[0;36mBlock.reduce\u001b[1;34m(self, func)\u001b[0m\n\u001b[0;32m    371\u001b[0m \u001b[39m@final\u001b[39m\n\u001b[0;32m    372\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mreduce\u001b[39m(\u001b[39mself\u001b[39m, func) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mlist\u001b[39m[Block]:\n\u001b[0;32m    373\u001b[0m     \u001b[39m# We will apply the function and reshape the result into a single-row\u001b[39;00m\n\u001b[0;32m    374\u001b[0m     \u001b[39m#  Block with the same mgr_locs; squeezing will be done at a higher level\u001b[39;00m\n\u001b[0;32m    375\u001b[0m     \u001b[39massert\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mndim \u001b[39m==\u001b[39m \u001b[39m2\u001b[39m\n\u001b[1;32m--> 377\u001b[0m     result \u001b[39m=\u001b[39m func(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mvalues)\n\u001b[0;32m    379\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mvalues\u001b[39m.\u001b[39mndim \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m    380\u001b[0m         res_values \u001b[39m=\u001b[39m result\n",
      "File \u001b[1;32mc:\\Users\\lalit\\anaconda3\\envs\\environment\\lib\\site-packages\\pandas\\core\\frame.py:11139\u001b[0m, in \u001b[0;36mDataFrame._reduce.<locals>.blk_func\u001b[1;34m(values, axis)\u001b[0m\n\u001b[0;32m  11137\u001b[0m         \u001b[39mreturn\u001b[39;00m np\u001b[39m.\u001b[39marray([result])\n\u001b[0;32m  11138\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m> 11139\u001b[0m     \u001b[39mreturn\u001b[39;00m op(values, axis\u001b[39m=\u001b[39maxis, skipna\u001b[39m=\u001b[39mskipna, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n",
      "File \u001b[1;32mc:\\Users\\lalit\\anaconda3\\envs\\environment\\lib\\site-packages\\pandas\\core\\nanops.py:85\u001b[0m, in \u001b[0;36mdisallow.__call__.<locals>._f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     81\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\n\u001b[0;32m     82\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mreduction operation \u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00mf_name\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m not allowed for this dtype\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m     83\u001b[0m     )\n\u001b[0;32m     84\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 85\u001b[0m     \u001b[39mreturn\u001b[39;00m f(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m     86\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mValueError\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     87\u001b[0m     \u001b[39m# we want to transform an object array\u001b[39;00m\n\u001b[0;32m     88\u001b[0m     \u001b[39m# ValueError message to the more typical TypeError\u001b[39;00m\n\u001b[0;32m     89\u001b[0m     \u001b[39m# e.g. this is normally a disallowed function on\u001b[39;00m\n\u001b[0;32m     90\u001b[0m     \u001b[39m# object arrays that contain strings\u001b[39;00m\n\u001b[0;32m     91\u001b[0m     \u001b[39mif\u001b[39;00m is_object_dtype(args[\u001b[39m0\u001b[39m]):\n",
      "File \u001b[1;32mc:\\Users\\lalit\\anaconda3\\envs\\environment\\lib\\site-packages\\pandas\\core\\nanops.py:404\u001b[0m, in \u001b[0;36m_datetimelike_compat.<locals>.new_func\u001b[1;34m(values, axis, skipna, mask, **kwargs)\u001b[0m\n\u001b[0;32m    401\u001b[0m \u001b[39mif\u001b[39;00m datetimelike \u001b[39mand\u001b[39;00m mask \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    402\u001b[0m     mask \u001b[39m=\u001b[39m isna(values)\n\u001b[1;32m--> 404\u001b[0m result \u001b[39m=\u001b[39m func(values, axis\u001b[39m=\u001b[39maxis, skipna\u001b[39m=\u001b[39mskipna, mask\u001b[39m=\u001b[39mmask, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    406\u001b[0m \u001b[39mif\u001b[39;00m datetimelike:\n\u001b[0;32m    407\u001b[0m     result \u001b[39m=\u001b[39m _wrap_results(result, orig_values\u001b[39m.\u001b[39mdtype, fill_value\u001b[39m=\u001b[39miNaT)\n",
      "File \u001b[1;32mc:\\Users\\lalit\\anaconda3\\envs\\environment\\lib\\site-packages\\pandas\\core\\nanops.py:477\u001b[0m, in \u001b[0;36mmaybe_operate_rowwise.<locals>.newfunc\u001b[1;34m(values, axis, **kwargs)\u001b[0m\n\u001b[0;32m    474\u001b[0m         results \u001b[39m=\u001b[39m [func(x, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs) \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m arrs]\n\u001b[0;32m    475\u001b[0m     \u001b[39mreturn\u001b[39;00m np\u001b[39m.\u001b[39marray(results)\n\u001b[1;32m--> 477\u001b[0m \u001b[39mreturn\u001b[39;00m func(values, axis\u001b[39m=\u001b[39maxis, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\lalit\\anaconda3\\envs\\environment\\lib\\site-packages\\pandas\\core\\nanops.py:646\u001b[0m, in \u001b[0;36mnansum\u001b[1;34m(values, axis, skipna, min_count, mask)\u001b[0m\n\u001b[0;32m    643\u001b[0m \u001b[39melif\u001b[39;00m dtype\u001b[39m.\u001b[39mkind \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mm\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m    644\u001b[0m     dtype_sum \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mdtype(np\u001b[39m.\u001b[39mfloat64)\n\u001b[1;32m--> 646\u001b[0m the_sum \u001b[39m=\u001b[39m values\u001b[39m.\u001b[39;49msum(axis, dtype\u001b[39m=\u001b[39;49mdtype_sum)\n\u001b[0;32m    647\u001b[0m the_sum \u001b[39m=\u001b[39m _maybe_null_out(the_sum, axis, mask, values\u001b[39m.\u001b[39mshape, min_count\u001b[39m=\u001b[39mmin_count)\n\u001b[0;32m    649\u001b[0m \u001b[39mreturn\u001b[39;00m the_sum\n",
      "File \u001b[1;32mc:\\Users\\lalit\\anaconda3\\envs\\environment\\lib\\site-packages\\numpy\\core\\_methods.py:49\u001b[0m, in \u001b[0;36m_sum\u001b[1;34m(a, axis, dtype, out, keepdims, initial, where)\u001b[0m\n\u001b[0;32m     47\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_sum\u001b[39m(a, axis\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, dtype\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, out\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, keepdims\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m,\n\u001b[0;32m     48\u001b[0m          initial\u001b[39m=\u001b[39m_NoValue, where\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m):\n\u001b[1;32m---> 49\u001b[0m     \u001b[39mreturn\u001b[39;00m umr_sum(a, axis, dtype, out, keepdims, initial, where)\n",
      "\u001b[1;31mTypeError\u001b[0m: can only concatenate str (not \"int\") to str"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "\n",
    "def combine_csvs(input_folder, output_file):\n",
    "    all_csvs = glob.glob(os.path.join(input_folder, '**/*.csv'), recursive=True)\n",
    "\n",
    "    if not all_csvs:\n",
    "        print(\"No CSV files found.\")\n",
    "        return\n",
    "\n",
    "    # Initialize an empty DataFrame to store the sum\n",
    "    sum_df = pd.DataFrame()\n",
    "\n",
    "    # Iterate through all CSV files\n",
    "    for csv in all_csvs:\n",
    "        # Read the CSV file\n",
    "        df = pd.read_csv(csv)\n",
    "\n",
    "        # Sum the values in each column\n",
    "        sum_series = df.sum()\n",
    "\n",
    "        # Get the folder name from the file path\n",
    "        folder_name = os.path.basename(os.path.dirname(csv))\n",
    "\n",
    "        # Add the sum Series to the sum DataFrame with the folder name as column name\n",
    "        sum_df[folder_name] = sum_series\n",
    "\n",
    "    # Save the sum DataFrame to the output CSV file\n",
    "    sum_df.to_csv(output_file, index=False)\n",
    "    print(f\"Combined and summed {len(all_csvs)} CSV files into {output_file}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    input_folder = \"C:/Riskscape_Projects/getting-started/output\"\n",
    "    output_csv = \"C:/Riskscape_Projects/getting-started/output/combined_sum_2.csv\"\n",
    "\n",
    "    combine_csvs(input_folder, output_csv)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "\n",
    "def combine_csvs(input_folder, output_file):\n",
    "    all_csvs = glob.glob(os.path.join(input_folder, '**/*.csv'), recursive=True)\n",
    "\n",
    "    if not all_csvs:\n",
    "        print(\"No CSV files found.\")\n",
    "        return\n",
    "\n",
    "    # Initialize an empty DataFrame to store the sum\n",
    "    sum_df = pd.DataFrame()\n",
    "\n",
    "    # Iterate through all CSV files\n",
    "    for csv in all_csvs:\n",
    "        # Read the CSV file\n",
    "        df = pd.read_csv(csv)\n",
    "\n",
    "        # Convert columns to numeric type (ignoring non-numeric values)\n",
    "        df = df.apply(pd.to_numeric, errors='coerce')\n",
    "\n",
    "        # Sum the values in each column, ignoring NaN values\n",
    "        sum_series = df.sum(skipna=True)\n",
    "\n",
    "        # Get the folder name from the file path\n",
    "        folder_name = os.path.basename(os.path.dirname(csv))\n",
    "\n",
    "        # Add the sum Series to the sum DataFrame with the folder name as column name\n",
    "        sum_df[folder_name] = sum_series\n",
    "\n",
    "    # Save the sum DataFrame to the output CSV file\n",
    "    sum_df.to_csv(output_file, index=False)\n",
    "    print(f\"Combined and summed {len(all_csvs)} CSV files into {output_file}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    input_folder = \"C:/Riskscape_Projects/getting-started/output\"\n",
    "    output_csv = \"C:/Riskscape_Projects/getting-started/output/combined_sum_1.csv\"\n",
    "\n",
    "    combine_csvs(input_folder, output_csv)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "environment",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
